 Assigning a key to a value is called mapping.

HASH TABLE TRUE DEFINITION : 
their various object having key-value pairs suppose, now two objects can have same value for value , but no two objects shall have key with same value. A hash table is used to bind a key with a value pair. ie. if we know the key, we can fetch the value of its corresponding value. 

hash function takes a key and based on that evaluates a hash(array index) at which the value corresponding to the key will be stored.

NOTE : how to perform better comparison fast ?? if we have evaluated hash values of x and y suppose, then if hash(x) != hash(y) => x != y but if hash(x) == hash(y) then x might be equal to y.

HASH COLLISION : when two objects hash to the same value.

a key is said to be HASHABLE if its FIXID ie. immutable and does not result to different hash values at different instance of calling the hash function. 

values used in  hash generation should not contain changing values so that a hash function always generates the same hash for an object.

A hash table is a fancy name for an array.
Hash function gives us an index.. as simple as that

NOW the complexity and prevension of hash collision is upon how good our hash function is.

>> Key vs Value vs Hash :
	- key and value have to be two attributes of objects in which key is unique and hash is the index generated on the basis of the key. Two objects can have same Values but there should be no same Key value.

How to prevent hash collision ??

>>>> LOAD FACTOR THRESHHOLD : load factor is the (number of filled slots/size of table) and threshold is the max value of load factor after which table is to resized.

hash collision resolution techniques : 
		> Seperate Chaining : seperate chaining maintains a data structure(usually linked list) to hold all the different values which hash to a same value. hence each and evey index of hash table array actually holds a root to a linked list. Seperate chaining is quiet simple and not too complicated.
bucket ??
- which ever ds we are using to store at a particular index is known as bucket.

		> Open addressing : deals with hash collition by finding another place in the hash table for the object to go , by offsetting it from the position to which it hashed to. Hence if position in array is taken already, the data will be stored in a seperate position.

		here we make a probing function along with hash function and this probing function defines where the next position is when we are given an index is already hashed. hence we add the value generated by the probing function to the current hash value to get the next position.These functions have functions(ax+b etc) in them to determine the next index. on the basis of the type of the function used in the probing method, the types are :

				- Linear Probing  : P(x) = ax+b where a and b are constants and x is an incrementing value(starting 1 and incrementing by 1).so next good hash = H(x) + P(x)

				- Quadratic Probing : P(x)= ax^2 +b where a and b are constants and x is an incrementing value(starting 1 and incrementing by 1). so next good hash = H(x) + P(x)

				- Double Hashing : P(k,x) = x*H2(k) where, H2(k) is a secondary hash function so using the secondary hash functino and value of the key, we determine the value of next hash.so next good hash = H(x) + P(x)

				- Pseudo Random Number Generator : P(k,x) = x*RNG(H(k),x) where RNG(H(k),x) is a random number generator function which generates value from H(k) and increments the value by x each time.so next good hash = H(x) + P(x)

NOTE  : that after generating a probing function and adding the probing value to the hash for the final step of finding the next suited hash, we mod by the size of table so that the hash we get is in the range of the table size. Also x in the above scenoario is so that for every next time we call probing function to find an alternative hash, it goes one step further.

NOTE that the array is to be doubled in size as it begins to fill up and this is very important part of hash table to maintain functionalit of a dynamic array.

CHAOS WITH CYCLES IN PROBING :
	> note that there might be a scinario that the probing sequence keeps iterating between certian fixed values causing an infinite loop.
	> eg. we make a probing function that is : H(x)+12 % l (where l is the size of the hash table) the issue there is that  this will lead to certian values being cycled infinitely in search for next spot in the table which is toxic. 
	> the solution is that we make probing function that does not cause this. 

	so if N is the size of the hash table, and P(x)= ax , then a and N should have a GCD of 1 for the P(x) to not cause cycles. GCD of 6 and 9 is 3 on the other hand that of 7 and 3 is 1.

	so if a and N have a GCD of 1, it will always find a spot in the hash table.

Summarise, a linear probing function P(x) = ax should consider value of a such that a and N should have GCD of 1 to cover all the values the given N range and hence avoid cycle. Also, x is a value that is 1 initially and is incremented by 1 every time to find the next hash value.

NOTE after probing to get the index in given range : new hash = (H(k) + P(x))%size of array

>> DOUBLE hashing :
	in double hashing , we probe according to a constant multiple of another hash function, specifically:
		P(k,x) = x * H2(K)%size where x is constantly incrementing value.
		H2(k) is another hash function that is given a key with same datatype that H1 recieved key given to the first hash function for probing.
		ie. if H1() takes int key, H2() will also accept int key.
		and H2(k)%size == delta.

		SO here the variable 'a' is changing based on the key only. and like always, x increments by 1 everytime the probing function is called forth.
 NOTE : DOUBLE hashing actually reduces to linear probing. IN linear probing 'a' is determined beforehand whereas, in double hashing H2(k) is 		
 		evaluated during runtime.

 		here also there can be chaos with cycles.

 		- so how do we ensure there are no cycles ??
 			we make table size a prime number and we consider a variable delta = H2(k) mod N and if delta == 0 guaranteed cycle and in such case we make it 1.
			 so hence hash with double hashhing looks like : 
			 (H1(k))mod N, (H1(k)+delta)mod N, (H1(k)+2delta)mod N, (H1(k)+3delta)mod N.... and so onn.
             here the number 1,2, 3 etc are x actually that increments every time.

			note that we keep chekcking value of delta, and if its 0, we just replace it with 1.
			The above sequence will go through all the indices of a given table. 
		
		- Constructing H2(k) :
				H1() is made by us in accordance with requirement, but H2() for any datatype can be piced from simple predefined hashfunctions called as universal hash 
				functions. These are simple and can be used since H2() does not have to requirement specific.

		- Note that the table size has to be prime everytime , even after we expand the size of table.


HOW TO FIX CHAYOS WITH CYCLES : 
	
	- Linear Probing(ax) : a and size of table should be Relatively Prime.

	- Quadratic Probing(ax^2 + bx) : 
			- let P(x) = x^2 and keep table size prime number > 3 and also load factor = alpha <= 1/2.
				or
			- let P(x) = (x^2 +x)/2 and keep the table size a power of two(this one looks good) here LoadFactor = 0.4(not fixed)
				or
			- let P(x) = (-1^x)*x^2 and keep the table size a prime N where N = 2 mod 4(forget this one)

	- Double Hashing(x*H2(k)) :
			- Keeping the table size a prime number , delta is evaluated :
					delta = H2(k) % sizeOfTable
				and the sequecence for searching :
					(H1(k))mod N, (H1(k)+delta)mod N, (H2(k)+2delta)mod N, (H2(k)+3delta)mod N.... and so onn.
				everytime delta == 0 , make delta = 1
				this is because delta ==0 means there will be cycle.
				and the 1,2,3 incrementing value before delta is actually x.


NOTE : when the threashhold for the table is exceeded , the table size should be increased in a way that does not affect the 
		probing function or the hash function. 
		- So make the next table size in accordance with probing function already defined so that there is no cycle.
		- The values in the previous tables are to be reevaluated and placed in the new table.
		- since table size also determines the position of the elements in the table, hence the position of elements will be different form their position from the previous table.


>> REMOVING FROM A HASH TABLE WITH Open Addressing :
		> Their is a very big problem with removing in hash table with naive way
			- in a hash table node1 and node 2 are two elements with keys k1 and k2
			- suppose k1 and k2 hash to same position so while inserting k1 gets placed at index lets say 1 and now when k2 is to be placed, it will check that position
			  1 is already taken, so it will probe to say 3.
			- so now k1 is at 1 and k2 at position 3.
			- removing k1, we check the positoin of k1 and find k1 at postion 1 and remove it.
			- so now index 1 is null.
			- removing k2... NOTE that k2 will also first point to 1 and now since 1 is null, the search will end concludint that k2 is not present in table !!!!
			- So this removal is not acceptable since k2 does exist.
			- HENCE NAIVE REMOVAL IS NOT POSSIBLE.
			- How to fix that??

			TOMBSTONES and OPTIMISATION : tombstones are markers that mark a position to be a deleted element. So everytime an element is to be removed, it is replaced by a tombstone.
						so in the above eg. k1 will be removed, and at pos 1 tombstone will be placed, now when searching to remove k2, at 1 tombstone will be ignoded and next 
						parsed address will be searched. Hence tombstone are useful.

		> Tombstone facts :
			- Tombstones are counted as elements and note that will effect the load factor threshold and whenever the table will be resized, the tombstones will be removed in the new table.
			- Also while inserting elements, tombstones will be treated like null and if an element is probed to a tombstone, it will be given that position replacing tombstone.

			OPTIMISATION : when we encounter a tombstone , we can optimise our hash table by simply replacing the first tombstone that we encountered while searching with the value we find at the end of search.
			This way if that element is to be searched again, its much faster. also the replaced position is to be made null.